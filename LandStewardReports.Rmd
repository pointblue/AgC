---
title: |
  <img src="ReportRef/Images/PBLogo.png" style="width: 300px;">  
  <img src="ReportRef/Images/AgCLogo.png" style="width: 500px;">  
  Land Steward Report
author: "Avalon Cook and Lisa Eash"
date: "`r format(Sys.Date(), '%B %d %Y')`"
output:
  bookdown::html_document2:
    number_sections: FALSE
    toc: true
    toc_float: true
    toc_depth: 3  # Include up to level 2 headers
    self_contained: true
dev: png
params:
  project_name: STAN
---
```{r Setup, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, results='hide'}

#Created by: Avalon Cook
#Created: 20231214
#Updated: 20241126 (by AC)

source('packages.R')
source('functions.R')

#renv::restore() #CHECK add renv to this rproj?
data_path<-("Z:/Soils Team/AgC Data/Master Datasheets")

knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE, 
	error=FALSE)

convert_depths <- function(x) {
  sapply(strsplit(x, "_"), function(parts) {
    nums <- as.numeric(parts)
    nums <- round(nums * 0.393701)
    paste(nums, collapse = "-")
  })
}

depth_sentence <- function(depths.string) {
  paste0(
    "Depth increments from ",
    paste(depths.string, collapse = ", "),
    " inches were analyzed separately."
  ) |>
    sub(", ([^,]*)$", " and \\1", x = _)
  }

#gs4_auth_configure(api_key = 'AIzaSyBEULjhG3_r_ZX6F7ZKDEUQ5yOgUbKVh6o') #this auth key is linked to Avalon's account and should prevent from the user needing to manually authorize each time, like in the line below
```
```{r, project.summary}
#pulling in spatial data
spatial_path <- "Z:/Soils Team/AgC Data/Raw Data/Spatial Data/ZippedShapefiles" #define the location of ACTION GIS data

border_pattern <- paste0(params$project_name, "_border.zip") #specify the pattern of the border file
borderzip_file <- list.files(
  path = spatial_path,
  pattern = border_pattern,
  recursive = TRUE,
  full.names = TRUE) # Search for the matching file, recursively
temp_folder1 <- tempfile() #create a temp directory where the shapefile can be unzipped
unzip(borderzip_file, exdir = temp_folder1)
border_file<-list.files(temp_folder1, pattern = "\\_border.shp$", full.names = TRUE)
border<- read_sf(border_file) #read in project polygon

#repeat for sampling points
points_pattern <- paste0(params$project_name, "_pointsfinal.zip") 
pointszip_file <- list.files(
  path = spatial_path,
  pattern = points_pattern,
  recursive = TRUE,
  full.names = TRUE) 
temp_folder2 <- tempfile() 
unzip(pointszip_file, exdir = temp_folder2)
points_file<-list.files(temp_folder2, pattern = "\\_pointsfinal.shp$", full.names = TRUE)
points<- read_sf(points_file) 

#Reading in master datasheets and filtering by project of interest
list_dfs_field<-list.files(file.path(data_path, "FieldLevel", ""), pattern = "\\.csv$", full.names = TRUE)
FieldLevel<-list_dfs_field[which.max(as.Date(gsub("\\D","", list_dfs_field), format = "%Y%m%d"))]%>%
  read.csv()%>%
  filter(project_name == params$project_name)

list_dfs_point<-list.files(file.path(data_path, "PointLevel", ""), pattern = "\\.csv$", full.names = TRUE)
PointLevel<-list_dfs_point[which.max(as.Date(gsub("\\D","", list_dfs_point), format = "%Y%m%d"))]%>%
  read.csv()%>%
  filter(project_id == params$project_name)

list_dfs_design<-list.files(file.path(data_path, "ProjectDesign", ""), pattern = "\\.csv$", full.names = TRUE)
ProjectDesign<-list_dfs_design[which.max(as.Date(gsub("\\D","", list_dfs_design), format = "%Y%m%d"))]%>%
  read.csv()%>%
  filter(project_id == params$project_name)

#add project design datasheet, then assign all the variables created above

#Establishing variables for report structure
proj.protocol <- FieldLevel$rangec_cropc[1]
proj.inscore <- ProjectDesign$inference_score[1]
proj.propertyname <- ProjectDesign$ranch_name[1]
proj.implementationyear <- if(is.na(ProjectDesign$proj_practice_year[1])){""}
pract_codes<-read.csv('practice_abbreviations.csv')
practs_vec<-strsplit(ProjectDesign$conservation_practice[1], ",\\s*")[[1]]
practs_full<-pract_codes$Practice[match(practs_vec, pract_codes$Abbreviation)]
proj.practicetype <- format_list(practs_full)
proj.title <- paste0(proj.propertyname, ": ", proj.implementationyear, proj.practicetype)
```

# `r proj.propertyname` {.unlisted .unnumbered}
#### Conservation practice(s): `r proj.practicetype` {.unlisted .unnumbered}

## Background
Thank you for participating in the Agricultural Carbon Monitoring Program. Ag-C was developed to help practitioners conduct transparent, fit-for-purpose monitoring of aboveground and belowground carbon in response to common conservation practices. At the same time that it supports management efforts at the farm scale, Ag-C is designed to evaluate management effects on carbon at regional scales when data is aggregated network-wide in the secure Point Blue Science Cloud. The collected information, from management history to field measurements, will support greater understanding of commonly incentivized practice impact on ecosystem carbon. 

The Agricultural Carbon ("Ag-C") Monitoring Program was developed by the Soils Team at Point Blue Conservation Science to help practitioners conduct transparent, fit-for-purpose monitoring of carbon dynamics in response to rangeland and cropland management. This report reviews the initial measurement for the baseline carbon indicators measured at your agricultural site. Continued use of the Ag-C protocols over time can assess the impact of your conservation effort. 

This report reviews monitoring efforts to date for the carbon indicators measured at your agricultural site. Continued use of the Ag-C protocols over time can assess the long-term impact of your conservation effort. Find additional information and funding updates for continued use of the Ag-C Monitoring Program on [our landing page](https://www.pointblue.org/ag-c/). 

## Project Design
The Ag-C program offers a flexible approach to designing a monitoring program. This includes the option to select carbon indicators of interest, tailor methods to your goals and resources, and match project design elements to your context. Ag-C is made of two major components: Range-C to accommodate monitoring in rangeland systems and Crop-C to accommodate monitoring in cropland systems. At your site, `r proj.protocol` was used as the guiding framework for developing a monitoring plan.^[To learn more about designing a monitoring program with `r proj.protocol`, consult the [`r proj.protocol` Handbook](`r ifelse(proj.protocol=='Range-C', 'https://www.pointblue.org/?sdm_process_download=1&download_id=19991', 'https://www.pointblue.org/?sdm_process_download=1&download_id=20943')`)]

To support interpretability and comparability, `r proj.protocol` assigns each monitoring project an “inference score” which reflects how decisions made in the project design process impact the overall rigor and reliability of the resulting data. Inference scores range from 40 to 100, where a higher score generally reflects greater confidence in the project's findings or a more holistic characterization of carbon dynamics in the study site. Nonetheless, all `r proj.protocol` projects represent a minimum standard of rigor and reliability. 

### Your inference score

The monitoring plan developed for the `r paste0(proj.implementationyear, " ", proj.practicetype)` practice at `r proj.propertyname ` results in a `r proj.protocol` inference score of `r proj.inscore`. In addition to the indicators measured, their sampling densities, and the selected methods, the following design factors contributed to the score: 

```{r Dynamic text Baseline and Control, results='asis'}
if (ProjectDesign$control_baseline=="TRUE" & length(unique(border$plot_type))==2){cat(paste0("This ", proj.protocol, " project includes baseline monitoring before the conservation practice was implemented as well as parallel monitoring at an untreated control site.", "<br><br>"))}

if (ProjectDesign$control_baseline=="TRUE" & length(unique(border$plot_type))==1){cat(paste0("This ", proj.protocol, " project includes baseline monitoring before the conservation practice was implemented, but did not include parallel monitoring at an untreated control site.", "<br><br>"))}

if (ProjectDesign$control_baseline=="FALSE" & length(unique(border$plot_type))==2){cat(paste0("This ", proj.protocol, " project includes parallel monitoring at an untreated control site, but did not capture baseline conditions before practice implementation.", "<br><br>"))}
  
if (ProjectDesign$control_baseline=="FALSE" & length(unique(border$plot_type))==1){cat(paste0("This ", proj.protocol, " project did not capture baseline conditions before practice implementation and was not able to compare current conditions to an untreated control site. While we are still able to characterize current conditions now and into the future, the results will have limited interpretability for understanding the full scope of practice impact.", "<br><br>"))}
```
The most rigorous project design includes baseline monitoring before the conservation practice is implemented, as well as parallel monitoring at an untreated control site into the future. Although not logistically possible for every project, these elements together provide highly interpretable results. 
  
```{r, max depth and selection method, results = 'asis'}
depths.inches<-unique(PointLevel$target_depth)%>%convert_depths()
max.depth.inches <- max(as.numeric(sub(".*-", "", depths.inches)))

cat(paste0("Soil samples were taken to a target maximum depth of ", max.depth.inches, " inches. ", "<br><br>" ))

if (ProjectDesign$point_generation_method=="GIS"){
  cat("Sampling points were randomly selected within the monitoring boundary using mapping software and located in the field by GPS.")
}else{cat("Sampling points were randomly selected using the Range-C Point Selector tool and paced out in the field.")}
```


### Carbon indicators
The following table includes carbon indicators that were included in this monitoring project and their corresponding acronyms that will be used in the following tables, graphs, and maps. A description of each indicator and reported units are provided. 


```{r, updated}
proj.indicator.db<-read.csv("ReportRef/indicator_descriptions.csv", check.names=FALSE)#read in the indicator descriptions reference sheet

proj.indicators<-proj.indicator.db$Acronym

proj.indicator.table<-proj.indicator.db%>% 
  rowwise() %>%
  filter(!all(is.na(PointLevel[[CheckCol]])))%>%
  filter(!Acronym %in% c("Sand", "Silt", "Clay"))
```
```{r, , results='asis'}
if ("Extra" %in% proj.indicator.table$Status){
cat(paste0("Note that your project includes indicators that aren’t directly related to carbon dynamics. These indicators provide additional information about site dynamics but aren’t covered in the ", proj.protocol,  " handbook."))}
```
```{r}
ind.table.kbl<-proj.indicator.table%>%select(Indicator, Acronym, Description, `Final units`)

Table1<-kbl(ind.table.kbl,
      caption= "Description of carbon indicators",
      col.names = gsub("[.]", " ", x=names(ind.table.kbl)), 
      row.names = FALSE,
      vline = "|",
      linesep = "\\addlinespace",
      align= c('llll'))

Table1 %>% 
  kable_styling(position='center', full_width = T) %>%
  column_spec(1, width="1.25in")%>%
  column_spec(2, width="0.5in")%>%
  column_spec(3, width="2.5in")%>%
  column_spec(4, width="1.75in")%>%
  row_spec(0, bold=TRUE)%>%
  collapse_rows(columns = c(1, 3, 4), valign = "middle") #merges adjacent cells with identical values
```

### Spatial design
The interactive map below shows the boundaries of the study area for monitoring and how sampling points are distributed. 
```{r}
#spatial data was pulled in above. Use this chunk to render your map.

border <- st_transform(border, crs = 4326)
points <- st_transform(points, crs = 4326)
points$labels <- substr(points$name, nchar(points$name) - 1, nchar(points$name))

pal <- colorFactor(c("white","black"), c("T", "C"))

leaflet() %>%
  addProviderTiles(providers$Esri.WorldImagery) %>%
  addPolygons(data = st_zm(border),
              fillOpacity = 0,
              color = ~ pal(plot_type),
              opacity=1)%>%
     addLegend(
      pal = pal, 
      values = border$plot_type,
      title = "Plot Type",
      position = "bottomleft",
      labFormat = function(type, cuts, p) { 
      c("Treatment", "Control")[match(cuts, c("T", "C"))]
    })%>%
  addLabelOnlyMarkers(data=points,
                      label = points$labels, 
                      labelOptions = labelOptions(
                        noHide = TRUE, 
                        direction = "center",
                       offset = c(0, 0),
                      style = list(
                              "font-weight" = "bold", 
                              "padding" = "1px", 
                              "border-radius" = "4px"
                                                  )))


```
```{r Dynamic text generation 1, results='asis'}
#this section states which, if any, indicators were measured at every sampling point and removes them from the following legend table

allpoints.list <- proj.indicator.table$CheckCol[
  proj.indicator.table$CheckCol %in% names(PointLevel) &    # must exist
    sapply(proj.indicator.table$CheckCol, function(col) all(!is.na(PointLevel[[col]])))
]

allpoints.table <- proj.indicator.table %>%
  filter(CheckCol %in% allpoints.list)

if (length(allpoints.list)>0){
cat("The following indicators were measured at every sampling point:", paste(allpoints.table$Indicator, collapse = ", "), "<br><br>")}
```
```{r Dynamic text generation 2, indicator.legend, results='asis'}

if (identical(allpoints.list, proj.indicator.table)==FALSE){ #only proceed if some indicators were not measured at every point
  
  #identifying indicators that were measured at a subset of points
  subset.inds <- proj.indicator.table$CheckCol[ 
  proj.indicator.table$CheckCol %in% names(PointLevel) &    # must exist
    sapply(proj.indicator.table$CheckCol, function(col) any(is.na(PointLevel[[col]])))] 
  
  #checking if all those subset indicators were done at the same points -- if so we'll just list them instead of making a table
  if (all(apply(!is.na(PointLevel[subset.inds]), 1, function(x) all(x) | all(!x)))){ #returns TRUE if all subset indicators were measured at the same sampling points
    subset_points <- PointLevel$sample_id[complete.cases(PointLevel[subset.inds])]
    subset.inds.name<-proj.indicator.table$Indicator[proj.indicator.table$CheckCol %in% subset.inds]
    cat(paste0("The following indicators were measured at ", format_list(subset_points), ": ", format_list(subset.inds.name),"<br><br>"))
  }
  
  #CHECK Here is where we go back to generating the table for when not all subset inds were measured at the same point. Not relevant for current report deadline. Model based on pilot reports code when ready
  if (all(apply(!is.na(PointLevel[subset.inds]), 1, function(x) all(x) | all(!x)))==FALSE){ 
    cat("Indicators that were only measured at some sampling points are listed in the table below.")
    
    #might have to generate the table in a different chunk, don't remember
  }
  
}

```
```{r, other spatial design elements, results='asis'}
if (ProjectDesign$composite==TRUE){
  cat("Each soil sample was composed of smaller composited samples to capture small-scale variability at each sampling point. ")
}



#CHECK add statement for stratification? Not worried about it right now but may come back after deadline
```
```{r, depth increments, results='asis'}
#Do some conversions for a statement about max depth and depth increments
depth.increments.no <- ProjectDesign$depth_increments


if (depth.increments.no>1){
  cat("Depth increments from ", depths.string[1], " inches and ", depths.string[2], " inches were analyzed separately.")
  
  depth_sentence(depths.inches)
  
}
```
## Results
```{r}
#creating a vector of value names that match the names in PointLevel
if ("Tx" %in% proj.indicators==TRUE) {
  proj.indicators.SSC<-c(proj.indicator.table$CheckCol, "sand", "silt")
} else {proj.indicators.SSC <- proj.indicator.table$CheckCol}

PointLevel<-PointLevel%>% 
  mutate(plot_type = "T")#substr(sample_id, 6, 6)) #CHECK! should be temporary (will get built into PointLevel)

```
```{r results='asis', eval = "bulk_density" %in% proj.indicators.SSC}
asis_output("### Soil carbon stocks\\n") #CONDITIONAL HEADER

```

``` {r, RACA baselines, warning=FALSE, message=FALSE, include=FALSE}
raca_data<-reg_baseline(border)[[1]]%>% #use Lisa's function to get raca data for our region and extract the dataframe
  select(upedonid, SOCstock30)%>% #select relevant columns
  mutate(
    SOCstock30 = SOCstock30*0.4461, #convert metric to imperial
    plot_type = "raca", #adding this variable allows for binding to main dataset and faceting the graph below
    Stocks_Indicator = "org_c_stocks") #adding this helps later behavior when I filter based on carbon pool 

raca_summary<-reg_baseline(border)[[2]] #create an object that holds the raca summary values (mean, CI, and ecoregion)

```

``` {r, results='asis', eval = "bulk_density" %in% proj.indicators.SSC}
asis_output(

paste0("The following graph shows soil organic carbon stocks stored in the study area compared to other rangeland and cropland sites in your ecoregion: ", 
       raca_summary$ecoregion,
       ". These comparison values are from the [USDA’s Rapid Carbon Assessment dataset](https://www.nrcs.usda.gov/resources/data-and-reports/rapid-carbon-assessment-raca), and provide context for understanding how your site stacks up against other agricultural sites in comparable climates. As you continue implementing conservation practices, your soil organic carbon (SOC) stocks have the potential to increase, moving closer to the higher end of SOC stocks seen in your region.")

)
```
```{r, Calculating stocks}
#Calculating stocks on qualifying soil metrics
if ("bulk_density" %in% proj.indicators.SSC){ #CHECK this condition needs to be different when we get plant projects cause someone could have SOC% only but also have measured plants
stocks.inds <- c("total_c", "total_n", "org_c", "inorg_c", "maoc", "poc", "pon") #these are the columns that can be turned into stocks (CHECK hard coding these in for now. Not sure if there's a better solution)
for(col in intersect(proj.indicators.SSC, stocks.inds)) {
  new_col <- paste0(col, "_stocks")  # new column name
  PointLevel[[new_col]] <- PointLevel[[col]]*PointLevel$bulk_density*PointLevel$e_depth*0.4461 #calculating stocks in US tons / acre (percent to decimal cancels out) 
}
proj.indicators.SSC.stocks<- c(proj.indicators.SSC, paste0(intersect(proj.indicators.SSC, stocks.inds), "_stocks")) #add those new column names to my list of indicator columns

if (length(setdiff(intersect(proj.indicators.SSC, stocks.inds), c('poc_stocks', 'maoc_stocks')))>1){ #if the number of stocks indicators (minus poc and maoc) are greater than one, create a summed all stocks column
  
  PointLevel <- PointLevel %>%
  mutate(
    all_stocks = rowSums(
      select(., ends_with("_stocks"), -maoc_stocks, -poc_stocks), #create a column for all pools combined, but make sure you're not double-counting poc and maoc, since org_c should cover that
      na.rm = TRUE
    )
  )
  proj.indicators.SSC<-c(proj.indicators.SSC, "all_stocks")
}

}
```

```{r, formatting stocks data}
stocks_df <- PointLevel %>% #reformats so the dataframe is long with respect to the carbon stock pool
  pivot_longer(
    cols = contains("_stocks"), # Select columns to pivot
    names_to = "Stocks_Indicator",          # Name for the new column
    values_to = "Tons.Acre"              # values to populate the new column
  ) %>%
  bind_rows( #bind project stocks df to the raca dataset
  raca_data %>%
    mutate(
      sample_id = upedonid,
      Tons.Acre = SOCstock30,
      plot_type = plot_type,
      Stocks_Indicator = Stocks_Indicator,
      .keep = "none"   # keep only these renamed columns
    )
  )

```


```{r fig.cap="Average soil organic carbon stocks. The error bars around average values show the range of confidence based on data variability (95% confidence intervals). Data collected at your site are compared to USDA Rapid Carbon Assessment values for other agricultural lands in your ecoregion. Black dots in the background show individual sampling point values."}
if ("bulk_density" %in% proj.indicators.SSC.stocks){

#SOC stocks graphic comparing to RaCa baselines
    SOC_stocks_df<-stocks_df%>%filter(Stocks_Indicator=="org_c_stocks") #filter the stocks df for only SOC (including raca)
    
    #Define the desired order of x-axis values
    SOC_stocks_df$plot_type <- factor(SOC_stocks_df$plot_type, levels = c("T", "C", "raca"))
    
    #Define custom palette
    cbbPalette <- c("T" = "#384F8Dff", 
                    "C" = "#384F8D80", 
                    "raca"= "#db7821",  
                    "Sampling point values" = "black") 
    
    #Begin graph
    ggplot(SOC_stocks_df, aes(x = plot_type, y = Tons.Acre)) +
      
      # Jittered black points
      geom_point(aes(color = "Sampling point values"),
        alpha = 0.5,
        size = 3,
        position = position_jitter(width = 0.2, height = 0)
      ) +
      
      # Mean + 95% CI (colored by plot_type)
      stat_summary(
        fun.data = function(x) {
          mean_x <- mean(x, na.rm = TRUE)
          se_x <- sd(x, na.rm = TRUE) / sqrt(length(x[!is.na(x)]))
          ci <- 1.96 * se_x
          data.frame(
            y = mean_x,
            ymin = mean_x - ci,
            ymax = mean_x + ci
          )
        },
        geom = "pointrange",
        aes(color = plot_type),
        size = 1.5, #size of dot
        linewidth = 1.5, #thickness of CI line
        shape = 16
      ) +
      
      # Labels, axes, theme
      labs(
        x = "",
        y = "Soil Organic Carbon Stored (tons/acre)",
      ) +
      scale_color_manual(values = cbbPalette,
                         breaks = c("C", "T", "raca", "Sampling point values"),
                         labels = c(str_wrap("Control site average", width=21), 
                                    str_wrap("Treated site average", width=21),
                                    str_wrap(paste0(raca_summary$ecoregion, " average"), width=21),
                                    "Sampling point values"),
                         name = "" #don't need a label over the legend
      ) +
      
      # Custom x-axis labels
      scale_x_discrete(labels = c(
        "T" = "Treated site",
        "C" = "Control site",
        "raca" = str_wrap(paste0(raca_summary$ecoregion, " ag-lands"), width=28)
      )) +
      
      # Text labels for means
      stat_summary(
        fun = mean,
        geom = "shadowtext", #requires package shadowtext
        bg.color = "black", #text outline color
        bg.r = 0.15,  #thickness of outline
        aes(label = sprintf("%.1f", ..y..)), #change decimal places printed by altering the digit
        color = "#FFD700", #text color
        hjust = -0.5,
        vjust = 0.2,
        fontface = "bold",
        size = 4
      )+
      
      theme_minimal()

}
```
```{r, Stocks figure for all other pools, fig.cap=""}
#Placeholder
```
### All soil properties
The following table summarizes average values across the study area for all soil metric(s) included in your project. 
```{r Summarize non-stocks soil means} 

Project.Means <- PointLevel %>%
                    dplyr::group_by(plot_type) %>%
                    dplyr::summarise(across(all_of(proj.indicators.SSC.stocks), \(x) mean(x, na.rm = TRUE))) #find the mean for each indicator grouped by plot

Means.Pivot1<- Project.Means %>% pivot_longer(cols=all_of(proj.indicators.SSC.stocks), names_to ='Indicator') %>%
          pivot_wider(names_from = c("plot_type"), values_from = value)%>%#pivot so that indicators are row names and plot type and depth increment combinations are column names
           left_join( #add the units column (CHECK,)
    proj.indicator.table %>% select(CheckCol, UnitsTable),
    by = c("Indicator" = "CheckCol")
  ) %>%
  mutate(
    Units = case_when(
      Indicator %in% c("sand", "silt", "clay") ~ "%",           # special values
      str_ends(Indicator, "_stocks") ~ "tons/acre",             # ends with _stocks
      TRUE ~ UnitsTable                                          # default mapping
    )
  ) %>%
  select(-UnitsTable)%>% #clunky way of fixing units...not worth chasing down rn
  mutate(
    # remove _stocks for matching if present
    Indicator_base = str_remove(Indicator, "_stocks$")
  ) %>%
  left_join(
    proj.indicator.table %>% select(Acronym, CheckCol),
    by = c("Indicator_base" = "CheckCol")
  ) %>%
  mutate(
    Acronym = case_when(
      Indicator_base == "sand" ~ "Sand",
      Indicator_base == "silt" ~ "Silt",
      Indicator_base == "clay" ~ "Clay",
      TRUE ~ Acronym                                # default mapping
    )
  ) 

Means.Pivot<-Means.Pivot1%>%
  select(-Indicator_base, -Indicator)
          
my_order <- c("SOC", "MAOC", "POC", "BD", "pH", "Sand", "Silt", "Clay")

Soil.Means <- Means.Pivot %>% select(Acronym, Units, everything())%>% #reorder columns
              mutate( #all the rest allows me to specify an order for the first few Ag-C metrics, and leave the rest alone
                  order_helper = match(Acronym, my_order),
                  original_order = row_number()
                ) %>%
                arrange(is.na(order_helper), order_helper, original_order) %>%
                select(-order_helper, -original_order)
```
```{r}
#Create plot summary table
  if (length(unique(border$plot_type))==1) { # Use this table format if there's only a treatment site
    SummaryTable <- Soil.Means %>% filter(Units!='tons/acre')%>% #dont include stocks here
      kbl(caption = "Soil Metrics", digits = 2, col.names = c("Indicator", "Unit", "Treatment"))
  } 
  if (length(unique(border$plot_type))==2) { # Use this table format if there's a treatment and control site
    SummaryTable <- Soil.Means %>% filter(Units!='tons/acre')%>% #dont include stocks here
      kbl(caption = "Soil Metrics", digits = 2, col.names = c("Indicator", "Unit", "Control", "Treatment"))
  }


SummaryTable %>%
  kable_styling(position='center', full_width = F)%>%
  collapse_rows(columns = 2, valign = "middle") #merges adjacent cells with identical values

#Add standard error or deviation to this table? Is there a nice way to group this up into variability levels?
```

```{r Texture Explanation, results='asis', eval = "Tx" %in% proj.indicators}
asis_output("#### Soil texture\\n") #CONDITIONAL HEADER
```
```{r results='asis'}
if ("Tx" %in% proj.indicators){cat("The graphic below represents where each soil sample falls in a texture triangle, indicating the percentage of clay-sized, silt-sized, and sand-sized particles. The corresponding USDA texture categories are named inside the triangle. In general, we expect clays to store more SOC than sands.")}

```
```{r Texture T and C, results='asis'}
if ("Tx" %in% proj.indicators & length(unique(border$plot_type))==2){cat("Since this project includes a treated and control site, it's also important to note how well the texture values between plots 'match' one another - this helps us interpret differences in carbon dynamics between the sites. Two texture triangles are shown, one for the treated site, and one for the control site.")}

```
```{r fig.height=6, fig.cap="Texture triangle(s) showing texture classifications for samples in the study area."}
if ("Tx" %in% proj.indicators){ #only do any of this if texture was included as an indicator (med and high ACTION roadmaps)

  if (length(unique(border$plot_type))==1){ #make one triangle for plots with only T site
    
  texture <- PointLevel %>% 
    rename(SAND=sand, SILT=silt, CLAY=clay) %>%
    filter(!is.na(CLAY)) %>%
    filter(!is.na(SAND)) %>%
    filter(!is.na(SILT))
TT.plot(
  class.sys = "USDA.TT",
  tri.data = texture,
  #z.name = "org_c",
  col="darkblue",
  main = NA,
  grid.show = FALSE,
 class.lab.show="full",
 css.lab = c("Clay %", "Silt %", "Sand %"),
  arrows.show=TRUE,
 cex.axis = 0.8,
 cex.lab = 0.8,
 lwd.lab = 0.8,
# z.col.hue = 0.4,
# z.pch = 1,
 arrows.lty='blank',
 new.mar =c(5.1, 0.1, 0.02, 0.1) #bottom, left, top, right
) 
  }
  
  if (length(unique(border$plot_type))==2){ #make 2 triangles for plots with a T and a C site
  

    texture_T <- PointLevel %>% 
    rename(SAND=sand, SILT=silt, CLAY=clay) %>%
    filter(!is.na(CLAY)) %>%
    filter(!is.na(SAND)) %>%
    filter(!is.na(SILT)) %>%
    filter(plot_type == "T") #CHECK! This won't work right now until lisa adds this column to PointLevel
    
    texture_C <- PointLevel %>% 
    rename(SAND=sand, SILT=silt, CLAY=clay) %>%
    filter(!is.na(CLAY)) %>%
    filter(!is.na(SAND)) %>%
    filter(!is.na(SILT)) %>%
    filter(plot_type == "C") #CHECK! This won't work right now until lisa adds this column to PointLevel

#this parts funny; in order to get the two plots to show side by side, i have to save them as PNGs first; using a temp directory to keep the working directory clean
    
temp_dir<-tempdir()
TextureT_path <- file.path(temp_dir, "TextureT")
TextureC_path <- file.path(temp_dir, "TextureC")
         
png(TextureT_path)
TT.plot(
  class.sys = "USDA.TT",
  tri.data = texture_T,
 # z.name = "org_c",
  main = "Treated Site",
    col="darkblue",
  grid.show = FALSE,
 class.lab.show="full",
 css.lab = c("Clay %", "Silt %", "Sand %"),
 arrows.show=TRUE,
 cex.axis = 0.8,
 cex.lab = 0.8,
 lwd.lab = 0.8,
 z.col.hue = 0.4,
 z.pch = 1,
 arrows.lty='blank',
 new.mar = c(.2, 1, .2, 1) #bottom, left, top, right
) 
dev.off()

png(TextureC_path)
TT.plot(
  class.sys = "USDA.TT",
  tri.data = texture_C,
 # z.name = "org_c",
  main = "Control Site",
  grid.show = FALSE,
     col="darkblue",
 class.lab.show="full",
 css.lab = c("Clay %", "Silt %", "Sand %"),
  arrows.show=TRUE,
 cex.axis = 0.8,
 cex.lab = 0.8,
 lwd.lab = 0.8,
 z.col.hue = 0.4,
 z.pch = 1,
 arrows.lty='blank',
 new.mar = c(.2, 1, .2, 1) #bottom, left, top, right
) 
dev.off()

imgT <- rasterGrob(png::readPNG(TextureT_path), interpolate = TRUE)
imgC <- rasterGrob(png::readPNG(TextureC_path), interpolate = TRUE)

grid.arrange(imgT, imgC, ncol = 2)
  }
  
}


```



### Dynamic map: all measured values

The previous tables and figures report results averaged across the study area. Use the interactive map below to explore results at each sampling point. Hover over the layers symbol to select from included metrics -- click on a sampling point to see all measured values at that point. 

```{r Dynamic map}

if ("bulk_density" %in% proj.indicators.SSC.stocks){
stockscolumns<-grep("_stocks$", proj.indicators.SSC.stocks, value = TRUE) #gather the names of the stocks columns
}

proj.indicators.nonbiomass<-proj.indicators.SSC.stocks[!proj.indicators.SSC.stocks %in% c("AHB", "HRB", "AWB", "WRB")] #CHECK! irrelevant for now but will be important later...get the rest of the project indicators that can be reported not as stocks...this matters for depth increment stuff

if ("bulk_density" %in% proj.indicators.SSC.stocks) { #combine into one vector 
  dynamicmap.inds <- c(stockscolumns, proj.indicators.nonbiomass)
} else {
  dynamicmap.inds <- proj.indicators.nonbiomass
}

fixed_order <- c("org_c", "maoc", "poc", "inorg_c", "org_c_stocks", "maoc_stocks", "poc_stocks", "inorg_c_stocks", "bulk_density", "ph", "sand", "silt", "clay") #
dynamicmap.inds <- c(
  intersect(fixed_order, dynamicmap.inds),           # fixed values in order
  setdiff(dynamicmap.inds, fixed_order)             # remaining values
) #getting values in the desired display order

PointData.projDYNAMIC<-PointLevel%>%
  select(sample_id, plot_type, all_of(dynamicmap.inds))


points<-points%>%
  rename(sample_id=name)%>%
  select(sample_id, geometry)
DataMap.proj<-left_join(points, PointData.projDYNAMIC, by="sample_id")

base_colors <- rainbow(length(dynamicmap.inds)) #create a rainbow palette from which to create color ramps

#define labels for legend and popups
Means.Pivot1<-Means.Pivot1%>%
  mutate(legend = paste0(Acronym,ifelse(is.na(Units), "", paste0(" ", Units))))
legends_names <- setNames(Means.Pivot1$legend, Means.Pivot1$Indicator)
legends_names["sample_id"]<-"Sample ID" #forcing in value for sample ID

#create dataframe for point popups
    #used chat gpt for a lot of this cause I couldn't figure how to generate the tables row-wise so we're not stuck with a ton of NAs
    df_forpopup <- DataMap.proj %>%
        mutate(across(any_of(dynamicmap.inds), ~round(.x,2)))%>%
      rename_with(~ legends_names[.x], .cols = any_of(names(legends_names)))#%>%
    
    # Helper function to build HTML for a single row (GPT)
    build_popup_html <- function(row, cols) {
      vals <- row[cols]                   # select the relevant columns
      vals <- vals[!is.na(vals)]          # remove NAs
      vals <- lapply(vals, as.character)  # convert all to character
      if(length(vals) == 0) return("")    # in case all values are NA
      paste0(
        "<table>",
        paste0("<tr><td><b>", names(vals), "</b></td><td>", vals, "</td></tr>", collapse=""),
        "</table>"
      )
    }
    
    popupcols<-setdiff(names(df_forpopup), c("sample_id", "geometry", "plot_type", "plot_type")) #define column to be included in the popups
    
    # Apply row-wise
    df_forpopup$popup_html <- apply(
      df_forpopup, 1, 
      function(r) build_popup_html(r, popupcols)
    )


#color palette for plot borders
pal <- colorFactor(c("white","black"), c("T", "C"))
  
#create the leaflet map for plot borders
    DynamicMap<-leaflet()%>% #establishing the basemap first
      addProviderTiles(providers$Esri.WorldImagery) %>%
      addPolygons(data = st_zm(border),
              fillOpacity = 0,
              color = ~ pal(plot_type),
              opacity=1)%>%
      addLegend(
      pal = pal, 
      values = border$plot_type,
      title = "Plot Type",
      position = "bottomleft",
      labFormat = function(type, cuts, p) { 
      c("Treatment", "Control")[match(cuts, c("T", "C"))]
    })
  
    overlay_groups <- c()

  #start formatting legend values for the points
  for (i in seq_along(dynamicmap.inds)) {
    legend_name <- ifelse(dynamicmap.inds[i] %in% names(legends_names), 
                          legends_names[dynamicmap.inds[i]], 
                          dynamicmap.inds[i])
    
    #this prevents errors from being thrown when there are NAs 
    if (all(is.na(DataMap.proj[[dynamicmap.inds[i]]]))){domainz=c(0,1)
    }else{domainz=DataMap.proj[[dynamicmap.inds[i]]]}
    
    #establish color palette for points for different indicators -- a different raindbow color will be selected for each indicator
    pal<- colorNumeric(palette = colorRampPalette(c("white", base_colors[i]))(100), domain =domainz)

  #pipe the points into the map created for the plot borders
   DynamicMap<-  DynamicMap %>%
          addProviderTiles(providers$Esri.WorldImagery) %>%  # Add satellite imagery as the basemap
          addCircleMarkers(
            data = DataMap.proj,
            color = ~pal(get(dynamicmap.inds[i])),   # Apply the color scale to the SOC field
            opacity = 1,
            radius = 3,
            group = legend_name,
            label = DataMap.proj$sample_id,
            popup=df_forpopup$popup_html#popupTable(df_forpopup, 
                  #           zcol=popupcols, 
                  #           row.numbers = FALSE, 
                  #           feature.id = FALSE)
              )%>%
       addLegend(
            pal = pal, 
            values = DataMap.proj[[dynamicmap.inds[i]]],
            title = legend_name,
            group = legend_name
          )
   
   overlay_groups <- c(overlay_groups, legend_name)
  }
    
 DynamicMap <- DynamicMap %>%
  addLayersControl(
    overlayGroups = overlay_groups, # Groups to toggle
    options = layersControlOptions(collapsed = TRUE)
  )%>%hideGroup(setdiff(overlay_groups, "SOC %"))
   
    
DynamicMap

```

## Frequently Asked Questions

#### Why is monitoring soil organic carbon important?
Soil organic carbon makes up the majority of soil organic matter which provides a variety of services in agro-ecosystems. Soil organic carbon benefits soil organisms by creating a structured, porous environment. In turn, these soil organisms then increase fertility by cycling nutrients from waste materials, leading to higher productivity. Soils with higher levels of organic carbon have higher water holding capacity contributing to overall landscape resilience. Understanding how soil organic carbon changes in response to management practices across a variety of soils and climates, will help us prioritize lands for maximum conservation planting impact.

#### How can I interpret 1 ton of carbon per acre?
One ton of carbon per acre is equal to 3.67 metric tons of CO2 removed from the atmosphere, equivalent to 1 year of passenger car emissions. It's important to note that carbon stored in this report is always related to the sampling depth. While sampling to a 12-inch depth is an industry-standard minimum, much more carbon can be stored below a foot of soil.     

#### As a land steward, how do I use all of this information?
Ag-C data is designed to track changes in carbon storage and cycling over time in response to conservation practices. Over several monitoring cycles, land stewards can use this information to make adaptive management decisions. If time-series data is not yet available, comparing across different areas of your own farm or ranch is most informative. Explore the dynamic map to gauge how different sites across the study area differ in key metrics.    

Additionally, our team is working towards a reporting structure that will allow landowners to compare their Ag-C data to other sites within the network, especially to other enrolled farms and ranches in their region. As our database grows, network-wide and regional comparisons will provide an increasingly detailed understanding of differing practice impacts across spatial scales. An online user dashboard allowing Ag-C land stewards to view and compare their results is planned for launch in 2026. 

If you’d like to pursue options for implementing carbon-building practices, reaching out to your local NRCS office is a great start. You can find a service center in your county at [www.nrcs.usda.gov/contact/find-a-service-center](https://www.nrcs.usda.gov/contact/find-a-service-center). 

#### How can the data from my site contribute to agricultural conservation science?  

Currently, accurate predictions of conservation practice outcomes are limited due to a lack of sufficient data on how on-farm management interacts with local environmental conditions. The Ag-C Program will address this gap by creating a publicly accessible database that spans a broad geographic range and timescale. This resource will enhance our understanding of how farm-level climate and management practices influence conservation outcomes, improve our ability to predict results locally, and support the development of practical, user-friendly tools for producers.  

Participants have the option to contribute their data to the Ag-C Database, where it is securely stored in the Point Blue Science Cloud. Data owners select a sharing level they are comfortable with, ranging from private to open. Please visit [this link](https://form.jotform.com/250767021376053) to read about our data sharing policies and select a data sharing level for your project.  

Detailed management data advances the science of agricultural conservation by helping to tease out relationships between management activities and changes in soil health. If you choose to submit your data to the Ag-C Database, please consider filling out a [Management Questionnaire](https://form.jotform.com/243406539772160) to multiply the impact of your contribution.  

#### How can I continue monitoring my conservation practice over time?
Under the Ag-C framework, each conservation practice has its own recommended resampling interval that ranges from 1 year to 10 years, based on the expected impact of the practice over time^[Consult the [`r proj.protocol` Handbook](`r ifelse(proj.protocol=='Range-C', 'https://www.pointblue.org/?sdm_process_download=1&download_id=19991', 'https://www.pointblue.org/?sdm_process_download=1&download_id=20943')`) for more information about resampling intervals by conservation practice.]. Our team is always working to identify opportunities for continued monitoring for Ag-C participants. Contact our team if you're interested in pursuing support for future resampling events or if you have existing support for future monitoring and would like to continue participating in the Ag-C Monitoring Program.

## Conclusion
Thank you for your participation in the Ag-C Monitoring Program. For more information about project design, further interpretation of results, or to access the raw data from your study site, please reach out to [RangeC\@pointblue.org](mailto:RangeC@pointblue.org) or [CropC\@pointblue.org](mailto:CropC@pointblue.org). Our team is happy to engage with additional questions or feedback. Your participation and sharing data will launch new scientific understanding of conservation management and support improved incentive structures across the nation.